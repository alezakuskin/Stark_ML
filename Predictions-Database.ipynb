{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alezakuskin/Stark_ML/blob/Ions/Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "8YCdLt94xL-R"
   },
   "outputs": [],
   "source": [
    "#@title # Run this cell to get all dependencies and packages ready\n",
    "!pip install roman\n",
    "\n",
    "RunInColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "from itertools import compress\n",
    "from urllib import request, parse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import catboost\n",
    "import roman\n",
    "import joblib\n",
    "import mariadb\n",
    "import re\n",
    "\n",
    "# !git clone -b Ions https://github.com/alezakuskin/Stark_ML\n",
    "from Stark_ML.utils.terms import *\n",
    "\n",
    "if RunInColab:\n",
    "    from google.colab import output\n",
    "    def clear_output():\n",
    "        output.clear()\n",
    "else:\n",
    "    from IPython import display\n",
    "    def clear_output():\n",
    "        display.clear_output()\n",
    "        \n",
    "def predict_width(data_for_prediction):\n",
    "    '''\n",
    "    Get predicted Stark broadening parameters for input lines\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_for_prediction : pd.DataFrame, dataframe with any number of rows,\n",
    "        all values of input features filled in; with \"Element\", \"Wavelength\",\n",
    "        \"Z number\", \"w (A)\", \"d (A)\" columns.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    numpy.ndarray\n",
    "        A one-dimentional array with predicted values of broadening parameters in \\u212B\n",
    "    '''\n",
    "    #Importing pretrained models\n",
    "    model1 = xgboost.XGBRegressor()\n",
    "    model1.load_model('Stark_ML/XGB_A+I_Eraw_Raw_No.json')\n",
    "\n",
    "    model2 = xgboost.XGBRegressor()\n",
    "    model2.load_model('Stark_ML/XGB_A+I_Enorm_Aug_No.json')\n",
    "\n",
    "    model3 = catboost.CatBoostRegressor()\n",
    "    model3.load_model('Stark_ML/CatBoost_A+I_Enorm_Raw_No.json')\n",
    "\n",
    "    model4 = joblib.load('Stark_ML/LightGBM_A+I_Eraw_Raw_No.pkl')\n",
    "\n",
    "    model5 = joblib.load('Stark_ML/LightGBM_A+I_Enorm_Raw_Scaler.pkl')\n",
    "\n",
    "    #Loading Standard Scaler\n",
    "    scaler = joblib.load('Stark_ML/scaler_width.pkl')\n",
    "    \n",
    "    #Getting predictions\n",
    "    epsilon = 1e-3\n",
    "    #Models without energy normalization\n",
    "    pred1 = model1.predict(data_for_prediction.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    pred4 = model4.predict(data_for_prediction.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    #Models with energy normalization\n",
    "    data_for_prediction['E lower']    = energy_to_fraction(data_for_prediction, 'E lower')\n",
    "    data_for_prediction['E upper']    = energy_to_fraction(data_for_prediction, 'E upper')\n",
    "    data_for_prediction['Gap to ion'] = energy_to_fraction(data_for_prediction, 'Gap to ion')\n",
    "    pred2 = model2.predict(data_for_prediction.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    pred3 = model3.predict(data_for_prediction.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    pred5 = model5.predict(scaler.transform(data_for_prediction.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)'])))\n",
    "    preds = (pred1 + pred2 + pred3 + pred4 + pred5)/5\n",
    "    preds = (np.exp(preds) - 1) * epsilon\n",
    "    \n",
    "    return(preds)\n",
    "\n",
    "def predict_shift(data_for_prediction):\n",
    "    '''\n",
    "    Get predicted Stark shift parameters for input lines\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_for_prediction : pd.DataFrame, dataframe with any number of rows,\n",
    "        all values of input features filled in; with \"Element\", \"Wavelength\",\n",
    "        \"Z number\", \"w (A)\", \"d (A)\" columns.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    numpy.ndarray\n",
    "        A two-dimentional array with predicted values of both broadening (1-st column)\n",
    "        and shift (2nd column) parameters in \\u212B\n",
    "    '''\n",
    "    #Importing pretrained models\n",
    "    model = joblib.load('Stark_ML/RF_Both_Eraw_Aug_No.pkl')\n",
    "\n",
    "    #Get broadening predictions first\n",
    "    widths = predict_width(data_for_prediction)\n",
    "    \n",
    "    #Adjust input data\n",
    "    data_for_prediction['w (A)'] = widths\n",
    "    data_for_prediction = data_for_prediction[model.model.feature_names_in_]\n",
    "    \n",
    "    #Get shift predictions\n",
    "    preds = model.predict(data_for_prediction)\n",
    "    \n",
    "    return(np.column_stack((widths, preds)))\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_DB(username,\n",
    "                  password,\n",
    "                  server = \"laser365-1.chem.msu.ru\",\n",
    "                  port=3306,\n",
    "                  database = \"kurucz\"):\n",
    "    \n",
    "    conn = mariadb.connect(\n",
    "            user=username,\n",
    "            password=password,\n",
    "            host=server,\n",
    "            port=port,\n",
    "            database=database)\n",
    "    \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_element(symbol):\n",
    "    # List of all valid element symbols in the periodic table\n",
    "    valid_elements = [\n",
    "        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\n",
    "        \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\",\n",
    "        \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\",\n",
    "        \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\",\n",
    "        \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\",\n",
    "        \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\",\n",
    "        \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\",\n",
    "        \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\",\n",
    "        \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\",\n",
    "        \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\",\n",
    "        \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\",\n",
    "        \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n",
    "    ]\n",
    "    return symbol.capitalize() in valid_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------------------------\n",
    "###Working version\n",
    "###-----------------------------------\n",
    "def convert_species_request(s):\n",
    "    def parse_roman_part(part):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            return []\n",
    "        if '-' in part:\n",
    "            start, end = [p.strip() for p in part.split('-')]\n",
    "            return list(range(roman.fromRoman(start.upper())-1, roman.fromRoman(end.upper()) + 1))\n",
    "        return [roman.fromRoman(part.upper())-1]\n",
    "\n",
    "    def parse_ionization_stages(stages):\n",
    "        # Separate by commas, then handle each part\n",
    "        parts = re.split(r'\\s*,\\s*', stages)\n",
    "        ionization = []\n",
    "        for part in parts:\n",
    "            ionization.extend(parse_roman_part(part))\n",
    "        return ionization\n",
    "\n",
    "    elements = []\n",
    "    ionizations = []\n",
    "    chem_elems = s.split(';')\n",
    "    \n",
    "    for chem_elem in chem_elems:\n",
    "        match = re.match(r'([A-Za-z]{1,2})\\s*([ivx,\\s-]*)', chem_elem.strip(), re.IGNORECASE)\n",
    "        if match:\n",
    "            element = match.group(1).capitalize()\n",
    "            if is_valid_element(element) == False:\n",
    "                raise ValueError(f\"Chemical element symbol {element} is incorrect\")\n",
    "            if match.group(2).strip():\n",
    "                ionization = parse_ionization_stages(match.group(2))\n",
    "            else:\n",
    "                ionization = 'All'\n",
    "            elements.append(element)\n",
    "            ionizations.append(ionization)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input format\")\n",
    "    \n",
    "    return elements, ionizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agrq23ixTUAB",
    "outputId": "37259483-eed0-47b1-e395-e590a08c6beb"
   },
   "outputs": [],
   "source": [
    "#@title #Request data from DataBase\n",
    "spectra = \"Ti i; Ti ii; ti III\" #@param {type: \"string\"}\n",
    "#@markdown Examples of allowed spectra:\n",
    "#@markdown **Ar I** or **Mg I-IV** or **Fe I; Si IX,XI**\n",
    "\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Enter wavelength in *nm*:\n",
    "lower = 240 #@param {type: \"number\"}\n",
    "upper = 245 #@param {type: \"number\"}\n",
    "\n",
    "target = \"both\" #@param [\"broadening\", \"shift\", \"both\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Would you like to save lines that cannot be encoded automatically to a separate file\n",
    "\n",
    "save_for_manual_check = True #@param {type: \"boolean\"}\n",
    "\n",
    "elements, ionizations = convert_species_request(spectra)\n",
    "\n",
    "connection = connect_to_DB(username = '',\n",
    "                          password = '')\n",
    "cur = connection.cursor()\n",
    "DB_df = None\n",
    "for i in range(len(elements)):\n",
    "    el = elements[i]\n",
    "    ion = ionizations[i]\n",
    "    if ion != 'All':\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM mytestview2\n",
    "        WHERE airwl >= {lower}\n",
    "        AND airwl <= {upper}\n",
    "        AND el_name = '{el}'\n",
    "        AND ion_stage in {f\"({', '.join(map(str, ion))})\"}\n",
    "        '''\n",
    "    else:\n",
    "        query = f'''\n",
    "        SELECT *\n",
    "        FROM mytestview2\n",
    "        WHERE airwl >= {lower}\n",
    "        AND airwl <= {upper}\n",
    "        AND el_name = '{el}'\n",
    "        '''\n",
    "#     print(query)\n",
    "    cur.execute(query)\n",
    "    column_names = [desc[0] for desc in cur.description]\n",
    "    req_results = cur.fetchall()\n",
    "    req_results = pd.DataFrame(req_results, columns=column_names)\n",
    "    if not req_results.empty:\n",
    "        if DB_df is None:\n",
    "            DB_df = req_results\n",
    "        else:\n",
    "            DB_df = pd.concat([DB_df, req_results], ignore_index=True)\n",
    "# print(DB_df)\n",
    "cur.close()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_i = pd.read_excel(Stark_ML.__path__.__dict__['_path'][0] + '/Source_files/Stark_data.xlsx',\n",
    "                       sheet_name='Ions',\n",
    "                       usecols='A:BQ',\n",
    "                       nrows = 2\n",
    "                   )\n",
    "request_df = split_OK_check(DB_to_StarkML(DB_df, data_i), save_manual_check = save_for_manual_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #The main part\n",
    "#@markdown Currently your will get results on the NIST query above.\n",
    "\n",
    "#@markdown You can upload you own *.txt* file or manually sanitized *for_manual_check.txt* to the panel on the left and specify the filename:\n",
    "\n",
    "filename = 'requested_lines.txt' #@param {type:\"string\"}\n",
    "filename = 'Stark_ML/' + filename\n",
    "\n",
    "#@markdown Select whether you would like to get predictions for a single tempeature value or for a temperature range\n",
    "Temperature_mode = 'single' #@param ['single', 'range']\n",
    "\n",
    "#@markdown If you selected *range* in the previous field, specify all three parameters here:\n",
    "Low_T = 8000   #@param {type: \"number\"}\n",
    "High_T = 10000 #@param {type: \"number\"}\n",
    "T_step = 100  #@param {type: \"number\"}\n",
    "\n",
    "\n",
    "\n",
    "#Loading linelist\n",
    "try:\n",
    "    data_predictions = pd.read_csv(filename,\n",
    "                                   index_col = 0\n",
    "                                   )\n",
    "except:\n",
    "    data_predictions = pd.read_csv(filename[9:],\n",
    "                                     index_col = 0\n",
    "                                     )\n",
    "    \n",
    "#Data preprocessing\n",
    "data_predictions.insert(data_predictions.columns.get_loc('E upper')+1, 'Gap to ion', 0)\n",
    "data_predictions['Gap to ion'] = gap_to_ion(data_predictions, 'E upper')\n",
    "data_predictions = data_predictions\n",
    "\n",
    "if Temperature_mode == 'single':\n",
    "    dtypes = data_predictions.dtypes.to_dict()\n",
    "    for index, row in data_predictions.iterrows():\n",
    "        data_predictions.at[index, 'T'] = Low_T\n",
    "    data_predictions = data_predictions.astype(dtypes)\n",
    "\n",
    "if Temperature_mode == 'range':\n",
    "    dtypes = data_predictions.dtypes.to_dict()\n",
    "    Ts = np.arange(Low_T, High_T + 1, T_step)\n",
    "    for index, row in data_predictions.iterrows():\n",
    "        data_predictions.at[index, 'T'] = Low_T\n",
    "        for T in Ts:\n",
    "            if T == Low_T:\n",
    "                continue\n",
    "            row['T'] = T\n",
    "            data_predictions = pd.concat([data_predictions, row.to_frame().T], ignore_index=True)\n",
    "    data_predictions = data_predictions.astype(dtypes)\n",
    "data_predictions = data_predictions.sort_values(['Wavelength', 'T']).reset_index(drop = True)\n",
    "    \n",
    "#Get predictions\n",
    "if target == 'broadening':\n",
    "    preds = predict_width(data_predictions)\n",
    "    preds = pd.Series(preds, name = 'w (A)')\n",
    "if target == 'shift':\n",
    "    preds = predict_shift(data_predictions)[:, 1]\n",
    "    preds = pd.Series(preds, name = 'd (A)')\n",
    "if target == 'both':\n",
    "    preds = predict_shift(data_predictions)\n",
    "    preds = pd.DataFrame(preds, columns = ['w (A)', 'd (A)'])\n",
    "    \n",
    "    \n",
    "#building output file\n",
    "columns = ['Element', 'Charge', 'Wavelength', 'T', 'w (A)', 'd (A)']\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Select additional transition parameters you would like to include in output file\n",
    "Element_symbol = True  #@param {type: 'boolean'}\n",
    "Wavelength     = True  #@param {type: 'boolean'}\n",
    "Temperature    = True  #@param {type: 'boolean'}\n",
    "Charge         = True #@param {type: 'boolean'}\n",
    "\n",
    "results = pd.DataFrame(columns = list(compress(columns, [Element_symbol, Charge, Wavelength, Temperature,\n",
    "                                                         True if (target == 'broadening') | (target == 'both') else False,\n",
    "                                                        True if (target == 'shift') | (target == 'both') else False])))\n",
    "results = pd.concat(\n",
    "        [\n",
    "        data_predictions[list(compress(columns, [Element_symbol, Charge, Wavelength, Temperature]))],\n",
    "        preds,\n",
    "        ],\n",
    "    axis = 1\n",
    "    )\n",
    "results.to_csv(f'PREDICTED_{filename[9:-4]}.csv', index = False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robNHUoq0E3i"
   },
   "source": [
    "## Congratulations! If the previous cell finished execution without errors, you can now download <filename.csv> file with predicted values of Stark broadening parameter.\n",
    "\n",
    "### For more details refer to 'paper' or contact us: ale-zakuskin@laser.chem.msu.ru"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
