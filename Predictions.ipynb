{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alezakuskin/Stark_ML/blob/Ions/Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "8YCdLt94xL-R"
   },
   "outputs": [],
   "source": [
    "#@title # Run this cell to get all dependencies and packages ready\n",
    "!pip install roman\n",
    "\n",
    "RunInColab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "from itertools import compress\n",
    "from urllib import request, parse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import catboost\n",
    "import roman\n",
    "import joblib\n",
    "\n",
    "# !git clone -b Ions https://github.com/alezakuskin/Stark_ML\n",
    "from Stark_ML.utils.terms import *\n",
    "\n",
    "if RunInColab:\n",
    "    from google.colab import output\n",
    "    def clear_output():\n",
    "        output.clear()\n",
    "else:\n",
    "    from IPython import display\n",
    "    def clear_output():\n",
    "        display.clear_output()\n",
    "        \n",
    "def predict_width(data_for_prediction):\n",
    "    '''\n",
    "    Get predicted Stark broadening parameters for input lines\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_for_prediction : pd.DataFrame, dataframe with any number of rows,\n",
    "        all values of input features filled in; without \"Element\", \"Wavelength\",\n",
    "        \"Z number\", \"w (A)\", \"d (A)\" columns.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    numpy.ndarray\n",
    "        A one-dimentional array with predicted values of broadening parameters in \\u212B\n",
    "    '''\n",
    "    #Importing pretrained models\n",
    "    model1 = xgboost.XGBRegressor()\n",
    "    model1.load_model('Stark_ML/XGB_A+I_Eraw_Raw_No.json')\n",
    "\n",
    "    model2 = xgboost.XGBRegressor()\n",
    "    model2.load_model('Stark_ML/XGB_A+I_Enorm_Aug_No.json')\n",
    "\n",
    "    model3 = catboost.CatBoostRegressor()\n",
    "    model3.load_model('Stark_ML/CatBoost_A+I_Enorm_Raw_No.json')\n",
    "\n",
    "    model4 = joblib.load('Stark_ML/LightGBM_A+I_Eraw_Raw_No.pkl')\n",
    "\n",
    "    model5 = joblib.load('Stark_ML/LightGBM_A+I_Enorm_Raw_Scaler.pkl')\n",
    "\n",
    "    #Loading Standard Scaler\n",
    "    scaler = joblib.load('Stark_ML/scaler_width.pkl')\n",
    "    \n",
    "    #Getting predictions\n",
    "    epsilon = 1e-3\n",
    "    pred1 = model1.predict(data_for_prediction)\n",
    "    pred2 = model2.predict(data_for_prediction)\n",
    "    pred3 = model3.predict(data_for_prediction)\n",
    "    pred4 = model4.predict(data_for_prediction)\n",
    "    pred5 = model5.predict(scaler.transform(data_for_prediction))\n",
    "    preds = (pred1 + pred2 + pred3 + pred4 + pred5)/5\n",
    "    preds = (np.exp(preds) - 1) * epsilon\n",
    "    \n",
    "    return(preds)\n",
    "\n",
    "def predict_shift(data_for_prediction):\n",
    "    '''\n",
    "    Get predicted Stark shift parameters for input lines\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_for_prediction : pd.DataFrame, dataframe with any number of rows,\n",
    "        all values of input features filled in; without \"Element\", \"Wavelength\",\n",
    "        \"Z number\", \"w (A)\", \"d (A)\" columns.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    numpy.ndarray\n",
    "        A two-dimentional array with predicted values of both broadening (1-st column)\n",
    "        and shift (2nd column) parameters in \\u212B\n",
    "    '''\n",
    "    #Importing pretrained models\n",
    "    model = joblib.load('Stark_ML/RF_Both_Eraw_Aug_No.pkl')\n",
    "\n",
    "    #Get broadening predictions first\n",
    "    widths = predict_width(data_for_prediction)\n",
    "    \n",
    "    #Adjust input data\n",
    "    data_for_prediction['w (A)'] = widths\n",
    "    data_for_prediction = data_for_prediction[model.model.feature_names_in_]\n",
    "    \n",
    "    #Get shift predictions\n",
    "    preds = model.predict(data_for_prediction)\n",
    "    \n",
    "    return(np.column_stack((widths, preds)))\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mariadb\n",
      "  Downloading mariadb-1.1.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\torchcuda\\lib\\site-packages (from mariadb) (23.1)\n",
      "Downloading mariadb-1.1.10-cp311-cp311-win_amd64.whl (197 kB)\n",
      "   ---------------------------------------- 0.0/197.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/197.6 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 92.2/197.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  194.6/197.6 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 197.6/197.6 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mariadb\n",
      "Successfully installed mariadb-1.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mariadb\n",
    "conn = mariadb.connect(\n",
    "        user=\"alex\",\n",
    "        password=\"xkk_6yoen\",\n",
    "        host=\"laser365-1.chem.msu.ru\",\n",
    "        port=3306,\n",
    "        database=\"kurucz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agrq23ixTUAB",
    "outputId": "37259483-eed0-47b1-e395-e590a08c6beb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:00, 488.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines could not be encoded correctly. Please, check them manually in for_manual_check.txt\n",
      "84 lines were encoded correctly.\n"
     ]
    }
   ],
   "source": [
    "#@title #Request data from NIST\n",
    "spectra = 'Ti II' #@param {type: \"string\"}\n",
    "#@markdown Examples of allowed spectra:\n",
    "#@markdown **Ar I** or **Mg I-IV** or **All spectra** or **Fe I; Si IX,XI; Ni Co-like**\n",
    "\n",
    "#@markdown or **H-Ar I-II** or **Mg Li-like; Al Li-like-Be-like** or **Sc-Fe K-like-Ca-like** or **198Hg I**\n",
    "\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Enter wavelength in *nm*:\n",
    "lower = 240 #@param {type: \"number\"}\n",
    "upper = 260 #@param {type: \"number\"}\n",
    "\n",
    "target = \"both\" #@param [\"broadening\", \"shift\", \"both\"] {type:\"raw\"}\n",
    "\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Would you like to save lines that cannot be encoded automatically to a separate file\n",
    "\n",
    "save_for_manual_check = True #@param {type: \"boolean\"}\n",
    "\n",
    "nist_params = { # error if not commented and equals 0\n",
    "    'spectra': spectra,\n",
    "    'limits_type': 0,\n",
    "    'low_w': lower,\n",
    "    'upp_w': upper,\n",
    "    'unit': 1,\n",
    "    'de': 0,\n",
    "    'I_scale_type': 1,\n",
    "    'format': 3,\n",
    "    'line_out': 0,\n",
    "    'en_unit': 0,\n",
    "    'output': 0,\n",
    "    #'bibrefs': 1,\n",
    "    'page_size': 15,\n",
    "    'show_obs_wl': 1,\n",
    "    'show_calc_wl': 1,\n",
    "    #'unc_out': 0,\n",
    "    'order_out': 0,\n",
    "    'max_low_enrg': '',\n",
    "    'show_av': 2,\n",
    "    'max_upp_enrg': '',\n",
    "    'tsb_value': 0,\n",
    "    'min_str': '',\n",
    "    #'A_out': 0,\n",
    "    #'intens_out': 'off',\n",
    "    'max_str': '',\n",
    "    'allowed_out': 1,\n",
    "    'forbid_out': 1,\n",
    "    'min_accur': '',\n",
    "    'min_intens': '',\n",
    "    'conf_out': 'on',\n",
    "    'term_out': 'on',\n",
    "    'enrg_out': 'on',\n",
    "    'J_out': 'on',\n",
    "    #'g_out': 'on',\n",
    "    #'remove_js': 'on',\n",
    "    #'no_spaces': 'on',\n",
    "    #'show_diff_obs_calc': 0,\n",
    "    #'show_wn': 1,\n",
    "    #'f_out': 'off',\n",
    "    #'S_out': 'off',\n",
    "    #'loggf_out': 'off',\n",
    "    'submit': 'Retrieve Data',\n",
    "}\n",
    "\n",
    "url = 'https://physics.nist.gov/cgi-bin/ASD/lines1.pl?'\n",
    "data = parse.urlencode(nist_params)\n",
    "req =  request.Request(url+data)\n",
    "with request.urlopen(req) as resp:\n",
    "    df = pd.read_csv(resp, sep='\\t')\n",
    "if 'sp_num' in list(df.columns):\n",
    "    df = df.drop(df.loc[df['sp_num'] == 'sp_num'].index)\n",
    "\n",
    "data_i = pd.read_excel(Stark_ML.__path__.__dict__['_path'][0] + '/Source_files/Stark_data.xlsx',\n",
    "                       sheet_name='Ions',\n",
    "                       usecols='A:BQ',\n",
    "                       nrows = 2\n",
    "                   )\n",
    "request_df = split_OK_check(NIST_to_StarkML(df, data_i, spectra), save_manual_check = save_for_manual_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #The main part\n",
    "#@markdown Currently your will get results on the NIST query above.\n",
    "\n",
    "#@markdown You can upload you own *.txt* file or manually sanitized *for_manual_check.txt* to the panel on the left and specify the filename:\n",
    "\n",
    "filename = 'requested_lines.txt' #@param {type:\"string\"}\n",
    "filename = 'Stark_ML/' + filename\n",
    "\n",
    "#@markdown Select whether you would like to get predictions for a single tempeature value or for a temperature range\n",
    "Temperature_mode = 'range' #@param ['single', 'range']\n",
    "\n",
    "#@markdown If you selected *range* in the previous field, specify all three parameters here:\n",
    "Low_T = 8000   #@param {type: \"number\"}\n",
    "High_T = 10000 #@param {type: \"number\"}\n",
    "T_step = 100  #@param {type: \"number\"}\n",
    "\n",
    "\n",
    "\n",
    "#Loading linelist\n",
    "try:\n",
    "    data_predictions = pd.read_csv(filename,\n",
    "                                   index_col = 0\n",
    "                                   )\n",
    "except:\n",
    "    data_predictions = pd.read_csv(filename[9:],\n",
    "                                     index_col = 0\n",
    "                                     )\n",
    "    \n",
    "#Data preprocessing\n",
    "data_predictions.insert(data_predictions.columns.get_loc('E upper')+1, 'Gap to ion', 0)\n",
    "data_predictions['Gap to ion'] = gap_to_ion(data_predictions, 'E upper')\n",
    "data_predictions = data_predictions\n",
    "\n",
    "if Temperature_mode == 'single':\n",
    "    print('here')\n",
    "    dtypes = data_predictions.dtypes.to_dict()\n",
    "    for index, row in data_predictions.iterrows():\n",
    "        data_predictions.at[index, 'T'] = Low_T\n",
    "    data_predictions = data_predictions.astype(dtypes)\n",
    "\n",
    "if Temperature_mode == 'range':\n",
    "    dtypes = data_predictions.dtypes.to_dict()\n",
    "    Ts = np.arange(Low_T, High_T + 1, T_step)\n",
    "    for index, row in data_predictions.iterrows():\n",
    "        data_predictions.at[index, 'T'] = Low_T\n",
    "        for T in Ts:\n",
    "            if T == Low_T:\n",
    "                continue\n",
    "            row['T'] = T\n",
    "            data_predictions = pd.concat([data_predictions, row.to_frame().T], ignore_index=True)\n",
    "    data_predictions = data_predictions.astype(dtypes)\n",
    "data_predictions = data_predictions.sort_values(['Wavelength', 'T']).reset_index(drop = True)\n",
    "    \n",
    "#Get predictions\n",
    "if target == 'broadening':\n",
    "    preds = predict_width(data_predictions.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    preds = pd.Series(preds, name = 'w (A)')\n",
    "if target == 'shift':\n",
    "    preds = predict_shift(data_predictions.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))[:, 1]\n",
    "    preds = pd.Series(preds, name = 'd (A)')\n",
    "if target == 'both':\n",
    "    preds = predict_shift(data_predictions.drop(columns=['Element', 'Wavelength', 'Z number', 'w (A)', 'd (A)']))\n",
    "    preds = pd.DataFrame(preds, columns = ['w (A)', 'd (A)'])\n",
    "    \n",
    "    \n",
    "#building output file\n",
    "columns = ['Element', 'Charge', 'Wavelength', 'T', 'w (A)', 'd (A)']\n",
    "#@markdown\n",
    "\n",
    "#@markdown ###Select additional transition parameters you would like to include in output file\n",
    "Element_symbol = True  #@param {type: 'boolean'}\n",
    "Wavelength     = True  #@param {type: 'boolean'}\n",
    "Temperature    = True  #@param {type: 'boolean'}\n",
    "Charge         = True #@param {type: 'boolean'}\n",
    "\n",
    "results = pd.DataFrame(columns = list(compress(columns, [Element_symbol, Charge, Wavelength, Temperature,\n",
    "                                                         True if (target == 'broadening') | (target == 'both') else False,\n",
    "                                                        True if (target == 'shift') | (target == 'both') else False])))\n",
    "results = pd.concat(\n",
    "        [\n",
    "        data_predictions[list(compress(columns, [Element_symbol, Charge, Wavelength, Temperature]))],\n",
    "        preds,\n",
    "        ],\n",
    "    axis = 1\n",
    "    )\n",
    "results.to_csv(f'PREDICTED_{filename[9:-4]}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robNHUoq0E3i"
   },
   "source": [
    "## Congratulations! If the previous cell finished execution without errors, you can now download <filename.csv> file with predicted values of Stark broadening parameter.\n",
    "\n",
    "### For more details refer to 'paper' or contact us: ale-zakuskin@laser.chem.msu.ru"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
