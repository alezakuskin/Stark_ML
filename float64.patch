--- abstract_model.py.bak	2022-04-20 10:51:46.468755548 +0000
+++ abstract_model.py	2022-04-20 12:03:23.012472134 +0000
@@ -264,7 +264,7 @@
 
         results = []
         for batch_nb, data in enumerate(dataloader):
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
             output, M_loss = self.network(data)
             predictions = output.cpu().detach().numpy()
             results.append(predictions)
@@ -298,7 +298,7 @@
         res_explain = []
 
         for batch_nb, data in enumerate(dataloader):
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
 
             M_explain, masks = self.network.forward_masks(data)
             for key, value in masks.items():
@@ -460,8 +460,8 @@
         """
         batch_logs = {"batch_size": X.shape[0]}
 
-        X = X.to(self.device).float()
-        y = y.to(self.device).float()
+        X = X.to(self.device).double()
+        y = y.to(self.device).double()
 
         for param in self.network.parameters():
             param.grad = None
@@ -526,7 +526,7 @@
         np.array
             model scores
         """
-        X = X.to(self.device).float()
+        X = X.to(self.device).double()
 
         # compute model output
         scores, _ = self.network(X)
@@ -696,7 +696,7 @@
         self.network.eval()
         feature_importances_ = np.zeros((self.network.post_embed_dim))
         for data, targets in loader:
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
             M_explain, masks = self.network.forward_masks(data)
             feature_importances_ += M_explain.sum(dim=0).cpu().detach().numpy()
 
--- multitask.py.bak	2022-04-20 10:51:46.469755631 +0000
+++ multitask.py	2022-04-20 12:03:23.017472552 +0000
@@ -104,7 +104,7 @@
 
         results = {}
         for data in dataloader:
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
             output, _ = self.network(data)
             predictions = [
                 torch.argmax(torch.nn.Softmax(dim=1)(task_output), dim=1)
@@ -150,7 +150,7 @@
 
         results = {}
         for data in dataloader:
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
             output, _ = self.network(data)
             predictions = [
                 torch.nn.Softmax(dim=1)(task_output).cpu().detach().numpy()
--- pretraining.py.bak	2022-04-20 10:51:46.469755631 +0000
+++ pretraining.py	2022-04-20 12:03:23.019472720 +0000
@@ -299,7 +299,7 @@
         """
         batch_logs = {"batch_size": X.shape[0]}
 
-        X = X.to(self.device).float()
+        X = X.to(self.device).double()
 
         for param in self.network.parameters():
             param.grad = None
@@ -364,7 +364,7 @@
         np.array
             model scores
         """
-        X = X.to(self.device).float()
+        X = X.to(self.device).double()
         return self.network(X)
 
     def stack_batches(self, list_output, list_embedded_x, list_obfuscation):
@@ -397,7 +397,7 @@
         results = []
         embedded_res = []
         for batch_nb, data in enumerate(dataloader):
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
             output, embeded_x, _ = self.network(data)
             predictions = output.cpu().detach().numpy()
             results.append(predictions)
--- tab_model.py.bak	2022-04-20 10:51:46.470755715 +0000
+++ tab_model.py	2022-04-20 12:03:23.021472887 +0000
@@ -97,7 +97,7 @@
 
         results = []
         for batch_nb, data in enumerate(dataloader):
-            data = data.to(self.device).float()
+            data = data.to(self.device).double()
 
             output, M_loss = self.network(data)
             predictions = torch.nn.Softmax(dim=1)(output).cpu().detach().numpy()
--- tab_network.py.bak	2022-04-20 10:51:46.470755715 +0000
+++ tab_network.py	2022-04-20 12:14:03.545098583 +0000
@@ -843,7 +843,7 @@
         for feat_init_idx, is_continuous in enumerate(self.continuous_idx):
             # Enumerate through continuous idx boolean mask to apply embeddings
             if is_continuous:
-                cols.append(x[:, feat_init_idx].float().view(-1, 1))
+                cols.append(x[:, feat_init_idx].double().view(-1, 1))
             else:
                 cols.append(
                     self.embeddings[cat_feat_counter](x[:, feat_init_idx].long())
--- utils.py.bak	2022-04-20 10:51:46.471755799 +0000
+++ utils.py	2022-04-20 13:14:02.570414235 +0000
@@ -141,7 +141,7 @@
     need_shuffle, sampler = create_sampler(weights, y_train)
 
     train_dataloader = DataLoader(
-        TorchDataset(X_train.astype(np.float32), y_train),
+        TorchDataset(X_train.astype(np.float64), y_train),
         batch_size=batch_size,
         sampler=sampler,
         shuffle=need_shuffle,
@@ -154,7 +154,7 @@
     for X, y in eval_set:
         valid_dataloaders.append(
             DataLoader(
-                TorchDataset(X.astype(np.float32), y),
+                TorchDataset(X.astype(np.float64), y),
                 batch_size=batch_size,
                 shuffle=False,
                 num_workers=num_workers,
